{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import namedtuple\n",
    "from dgl.nn.pytorch import GATConv\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('graph', 'action', 'reward', 'next_graph', 'done'))\n",
    "\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save Transitions\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        samples = random.sample(self.memory, batch_size)\n",
    "        \n",
    "        graphs = [sample[0] for sample in samples]\n",
    "        actions = [sample[1] for sample in samples]\n",
    "        rewards = [sample[2] for sample in samples]\n",
    "        next_graphs = [sample[3] for sample in samples]\n",
    "        dones = [sample[4] for sample in samples]\n",
    "\n",
    "        ret_graph = dgl.batch(graphs)\n",
    "        ret_action = torch.stack(actions).reshape(-1, 1)\n",
    "        ret_reward = torch.Tensor(rewards).reshape(-1)\n",
    "        ret_next_graph = dgl.batch(next_graphs)\n",
    "        ret_dones = torch.Tensor(dones).reshape(-1)\n",
    "\n",
    "        \n",
    "        return ret_graph, ret_action, ret_reward, ret_next_graph, ret_dones\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Encoder\n",
    "\n",
    "\\begin{equation}\n",
    "h_{i}=\\mathrm{MLP}(o_{i})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObsEncoder(nn.Module):\n",
    "    def __init__(self, in_dim, o_dim=128, h_dim=512):\n",
    "        super(ObsEncoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_dim. h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, o_dim)\n",
    "    \n",
    "    def forward(self, o):\n",
    "        o = F.relu(self.fc1(o))\n",
    "        o = F.relu(self.fc2(o))\n",
    "        return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relational Kernel\n",
    "\n",
    "\\begin{equation}\n",
    "\\alpha_{i,j}^{m}=\\frac{\\exp(\\tau\\cdot \\mathbf{W}_{Q}^{m}h_{i}\\cdot(\\mathbf{W}_{K}^{m}h_{j})^\\top)}{\\sum_{k\\in\\mathbb{B}_{+i}}\\exp(\\tau\\cdot\\mathbf{W}_{Q}^{m}h_{i}\\cdot(\\mathbf{W}_{K}^{m}h_{k})^{\\top})}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "h_{i}^{'}=\\sigma\\left( \\mathrm{concat}_{m\\in M}\\left[ \\sum_{j\\in\\mathbb{B}_{+i}}\\alpha_{i,j}^{m}\\mathbf{W}_{v}^{m}h_{j} \\right] \\right)\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotGATLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(DotGATLayer, self).__init__()\n",
    "        self.fc_q = nn.Linear(in_dim, out_dim)\n",
    "        self.fc_k = nn.Linear(in_dim, out_dim)\n",
    "        self.fc_v = nn.Linear(in_dim, out_dim)\n",
    "        self.tau = 1/math.sqrt(out_dim)\n",
    "\n",
    "    def edge_attention(self, edges):\n",
    "        k = self.fc_k(edges.src['z'])\n",
    "        q = self.fc_q(edges.dst['z'])\n",
    "        a = (k*q).sum(-1, keepdims=True)*self.tau\n",
    "        return {'e': a}\n",
    "\n",
    "    def message_func(self, edges):\n",
    "        return {'z': edges.src['z'], 'e': edges.data['e']}\n",
    "    \n",
    "    def reduce_func(self, nodes):\n",
    "        s = nodes.mailbox['e']\n",
    "        alpha = F.softmax(s, dim=1)\n",
    "        v = self.fc_v(nodes.mailbox['z'])\n",
    "        h = torch.sum(alpha * v, dim=1)\n",
    "        return {'h': h, 'alpha': alpha.squeeze()}\n",
    "\n",
    "    def forward(self, g, z):\n",
    "        g.ndata['z'] = z\n",
    "        g.apply_edges(self.edge_attention)\n",
    "        g.update_all(self.message_func, self.reduce_func)\n",
    "        h = g.ndata.pop('h')\n",
    "        alpha = g.ndata.pop('alpha')\n",
    "        dummy = g.ndata.pop('z')\n",
    "        return h, alpha\n",
    "\n",
    "class MultiHeadDotGATLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_heads):\n",
    "        super(MultiHeadDotGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        h_dim = out_dim // num_heads\n",
    "        assert (h_dim*num_heads) == out_dim\n",
    "        for _ in range(num_heads):\n",
    "            self.heads.append(DotGATLayer(in_dim, h_dim))\n",
    "        self.merge = merge\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        hs, alphas = map(list, zip(*[head(g, h)\n",
    "                                     for head in self.heads]))\n",
    "        alpha = torch.stack(alphas).mean(0)\n",
    "        h = F.relu(torch.cat(hs, dim=1))\n",
    "        return h, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relational Kernel with Bayesian Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesGATLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim,\n",
    "                 se_dim=1, sigma=1e-15, sigma_0=1e15):\n",
    "        super(BayesGATLayer, self).__init__()\n",
    "        self.fc_q = nn.Linear(in_dim, out_dim)\n",
    "        self.fc_k = nn.Linear(in_dim, out_dim)\n",
    "        self.fc_v = nn.Linear(in_dim, out_dim)\n",
    "        self.tau = 1/math.sqrt(out_dim)\n",
    "\n",
    "        self.sigma = torch.tensor(sigma).type(torch.float32)\n",
    "        self.se_fc1 = nn.Linear(in_dim, se_dim)\n",
    "        self.se_fc2 = nn.Linear(se_dim, 1)\n",
    "        self.se_act = nn.ReLU()\n",
    "        self.sigma_0 = torch.tensor(sigma_0).type(torch.float32)\n",
    "        self.KL_backward = 0.\n",
    "\n",
    "    def edge_attention(self, edges):\n",
    "        k = edges.src['z']\n",
    "        k2 = self.se_fc1(k)\n",
    "        k2 = self.se_fc2(self.se_act(k2))\n",
    "        k = self.fc_k(k)\n",
    "        q = self.fc_q(edges.dst['z'])\n",
    "        a = (k*q).sum(-1, keepdims=True)*self.tau\n",
    "        \n",
    "        return {'e': a, 'p': k2}\n",
    "    \n",
    "    def message_func(self, edges):\n",
    "        return {'z': edges.src['z'], 'e': edges.data['e'], 'p': edges.data['p']}\n",
    "    \n",
    "    def reduce_func(self, nodes):\n",
    "        s = nodes.mailbox['e']\n",
    "        p = F.softmax(nodes.mailbox['p'], dim=1)\n",
    "        mean_prior = torch.log(p+1e-20)\n",
    "        alpha = F.softmax(s, dim=1)\n",
    "        logprobs = torch.log(alpha+1e-20)\n",
    "        if self.training:\n",
    "            mean_posterior = logprobs - self.sigma**2 / 2\n",
    "            out_weight = F.softmax(mean_posterior + self.sigma*torch.randn_like(logprobs), dim=1)\n",
    "            KL = torch.log(self.sigma_0 / self.sigma + 1e-20) + (\n",
    "                    self.sigma**2 + (mean_posterior - mean_prior)**2) / (2 * self.sigma_0**2) - 0.5\n",
    "        else:\n",
    "            out_weight = alpha\n",
    "            KL = torch.zeros_like(out_weight)\n",
    "        v = self.fc_v(nodes.mailbox['z'])\n",
    "        h = torch.sum(out_weight * v, dim=1)\n",
    "        return {'h': h, 'alpha': alpha.squeeze(), 'kl': KL.mean(dim=1)}\n",
    "\n",
    "    def forward(self, g, z):\n",
    "        g.ndata['z'] = z\n",
    "        g.apply_edges(self.edge_attention)\n",
    "        g.update_all(self.message_func, self.reduce_func)\n",
    "        self.KL_backward = g.ndata.pop('kl').mean()\n",
    "        h = g.ndata.pop('h')\n",
    "        alpha = g.ndata.pop('alpha')\n",
    "        dummy = g.ndata.pop('z')\n",
    "        return h, alpha\n",
    "\n",
    "class BayesMultiHeadGATLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, num_heads,\n",
    "                 se_dim=1, sigma=1e-15, sigma_0=1e15):\n",
    "        super(BayesMultiHeadGATLayer, self).__init__()\n",
    "        self.heads = nn.ModuleList()\n",
    "        assert (h_dim*num_heads) == out_dim\n",
    "        for _ in range(num_heads):\n",
    "            self.heads.append(BayesGATLayer(in_dim, h_dim,\n",
    "                                            se_dim, sigma, sigma_0))\n",
    "        self.merge = merge\n",
    "        self.KL_backward = 0.\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        hs, alphas = map(list, zip(*[head(g, h)\n",
    "                                     for head in self.heads]))\n",
    "        alpha = torch.stack(alphas).mean(0)\n",
    "        KL = [head.KL_backward for head in self.heads]\n",
    "        self.KL_backward = torch.mean(torch.stack(KL))\n",
    "        h = F.relu(torch.cat(hs, dim=1))\n",
    "        return h, alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DGN-R Agent\n",
    "\n",
    "\\begin{equation}\n",
    "Q(o_{i}, \\cdot)=\\mathrm{Linear}\\left(\\mathrm{concat}\\left[ h_{i}, h_{i}^{'}, h_{i}^{''} \\right]\\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathcal{L}_{\\mathrm{reg}}(\\theta)=\\frac{1}{M}\\sum_{m=1}^{M}D_{\\mathrm{KL}}\\left( \\mathcal{G}_{m}(O_{i,\\mathcal{C}};\\theta) || \\mathcal{G}_{m}(O_{i,\\mathcal{C}}';\\theta) \\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGN_Conv(nn.Module):\n",
    "    def __init__(self, obs_dim, h_dim=128, num_heads=8,\n",
    "                 target=False):\n",
    "        super(DGN_Conv, self).__init__()\n",
    "        self.encoder = ObsEncoder(in_dim=obs_dim, o_dim=h_dim)\n",
    "        self.conv1 = MultiHeadDotGATLayer(h_dim, h_dim, num_heads)\n",
    "        self.conv2 = MultiHeadDotGATLayer(h_dim, h_dim, num_heads)\n",
    "        self.target = target\n",
    "    \n",
    "    def forward(self, graph):\n",
    "        obs = graph.ndata['obs']\n",
    "        z1 = self.encoder(obs)\n",
    "        z2, _ = self.conv1(graph, z1)\n",
    "        z3, alpha = self.conv2(graph, z2)\n",
    "        out = torch.cat([z1, z2, z3], dim=1)\n",
    "        if self.target:\n",
    "            return out\n",
    "        return out, alpha\n",
    "\n",
    "class DGNAgent(nn.Module):\n",
    "    def __init__(self, n_agents, obs_dim, act_dim, h_dim=128,\n",
    "                 num_heads=8, gamma=0.96, batch_size=10,\n",
    "                 buffer_size=2*1e5, epsilon=0.6, episilon_min=0.01,\n",
    "                 decay_rate=0.996, lr=1e-4, neighbors=3,\n",
    "                 lamb=0.03, beta=0.01, *args, **kwargs):\n",
    "        super(DGNAgent, self).__init__()\n",
    "        self.conv_net = DGN_Conv(obs_dim, h_dim, num_heads)\n",
    "        self.target_conv = DGN_Conv(obs_dim, h_dim, num_heads, target=True)\n",
    "        self.q_net = nn.Linear(3*h_dim, act_dim)\n",
    "        self.target_q = nn.Linear(3*h_dim, act_dim)\n",
    "        self.target_conv.load_state_dict(self.conv_net.state_dict())\n",
    "        self.target_q.load_state_dict(self.q_net.state_dict())\n",
    "        self.optimizer = Adam(self.conv_net.parameters()+self.q_net.parameters(),\n",
    "                              lr=lr)\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.buffer = ReplayBuffer(buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.decay_rate = decay_rate\n",
    "        \n",
    "        self.n_agents = n_agents\n",
    "        self.n_act = act_dim\n",
    "        self.n_neighbor = neighbors\n",
    "        self.lamb = lamb  \n",
    "\n",
    "    def get_action(self, graph):\n",
    "        if random.random() < self.epsilon:\n",
    "            action = torch.randint(0, n_act, size=(self.n_agents,))\n",
    "        else:\n",
    "            q_value = self.q_net(graph)\n",
    "            action = q.argmax(dim=-1).detach()\n",
    "        self.epsilon = max(self.epsilon*self.decay_rate, self.epsilon_min)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def get_q(self, graph):\n",
    "        z, weight = self.conv_net(graph)\n",
    "        q = self.q_net(z)\n",
    "        return q, weight\n",
    "    \n",
    "    def get_target(self, graph):\n",
    "        z = self.target_conv(graph)\n",
    "        q = self.target_q(z)\n",
    "        return q\n",
    "    \n",
    "    def save_samples(self, g, a, r, n_g, t):\n",
    "        self.buffer.push(g, a, r, n_g, t)\n",
    "    \n",
    "    def fit(self):\n",
    "        if len(self.buffer) < self.batch_size*10:\n",
    "            return False, 0\n",
    "        \n",
    "        state, act, reward, n_state, done = self.buffer.sample(self.batch_size)\n",
    "        curr_qs, curr_weight = self.get_qs(state)\n",
    "        selected_qs = curr_qs.gather(1, act).reshape(-1)\n",
    "        next_qs = self.get_target(n_state).max(dim=1)[0].detach()\n",
    "        target = reward + self.gamma * next_qs * (1 - done)\n",
    "        \n",
    "        _, next_weight = self.get_qs(n_state)\n",
    "        KL = (curr_weight * torch.log(curr_weight/next_weight)).sum(-1)\n",
    "        \n",
    "        loss = F.mse_loss(curr_qs, target) + self.lamb*KL.mean()\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.target_update()\n",
    "        \n",
    "        return True, loss.item()\n",
    "    \n",
    "    def target_update(self):\n",
    "        for target, param in zip(self.target_conv.parameters(),\n",
    "                                  self.conv_net.parameters()):\n",
    "            target.data = (1-self.beta)*target.data + self.beta*param.data\n",
    "\n",
    "        for target, param in zip(self.q_net.parameters(),\n",
    "                                  self.target_q.parameters()):\n",
    "            target.data = (1-self.beta)*target.data + self.beta*param.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DGN-R Agent with Bayesian Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesDGN_Conv(nn.Module):\n",
    "    def __init__(self, obs_dim, h_dim=128, num_heads=8,\n",
    "                 se_dim=1, sigma=1e-15, sigma_0=1e15,\n",
    "                 target=False):\n",
    "        super(BayesDGN_Conv, self).__init__()\n",
    "        self.encoder = ObsEncoder(in_dim=obs_dim, o_dim=h_dim)\n",
    "        self.conv1 = BayesMultiHeadGATLayer(h_dim, h_dim, num_heads,\n",
    "                                            se_dim, sigma, sigma_0)\n",
    "        self.conv2 = BayesMultiHeadGATLayer(h_dim, h_dim, num_heads,\n",
    "                                            se_dim, sigma, sigma_0)\n",
    "        self.target = target\n",
    "        if self.target:\n",
    "            self.training = False\n",
    "\n",
    "    def forward(self, graph):\n",
    "        obs = graph.ndata['obs']\n",
    "        z1 = self.encoder(obs)\n",
    "        z2, _ = self.conv1(graph, z1)\n",
    "        z3, alpha = self.conv2(graph, z2)\n",
    "        out = torch.cat([z1, z2, z3], dim=1)\n",
    "        if self.target:\n",
    "            return out\n",
    "        return out, alpha\n",
    "    \n",
    "    def kl(self):\n",
    "        return self.conv1.KL_backward + self.conv2.KL_backward\n",
    "\n",
    "class BayesDGNAgent(nn.Module):\n",
    "    def __init__(self, n_agents, obs_dim, act_dim, h_dim=128,\n",
    "                 num_heads=8, gamma=0.96, batch_size=10,\n",
    "                 buffer_size=2*1e5, epsilon=0.6, episilon_min=0.01,\n",
    "                 decay_rate=0.996, lr=1e-4, neighbors=3,\n",
    "                 lamb=0.03, beta=0.01, rho=0.1,\n",
    "                 se_dim=1, sigma=1e-15, sigma_0=1e15,\n",
    "                 *args, **kwargs):\n",
    "        super(BayesDGNAgent, self).__init__()\n",
    "        self.conv_net = BayesDGN_Conv(obs_dim, h_dim, num_heads,\n",
    "                                      se_dim=1, sigma=1e-15, sigma_0=1e15)\n",
    "        self.target_conv = BayesDGN_Conv(obs_dim, h_dim, num_heads,\n",
    "                                         se_dim=1, sigma=1e-15, sigma_0=1e15,\n",
    "                                         target=True)\n",
    "        self.q_net = nn.Linear(3*h_dim, act_dim)\n",
    "        self.target_q = nn.Linear(3*h_dim, act_dim)\n",
    "        self.target_conv.load_state_dict(self.conv_net.state_dict())\n",
    "        self.target_q.load_state_dict(self.q_net.state_dict())\n",
    "        self.optimizer = Adam(self.conv_net.parameters()+self.q_net.parameters(),\n",
    "                              lr=lr)\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.buffer = ReplayBuffer(buffer_size)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.decay_rate = decay_rate\n",
    "        \n",
    "        self.n_agents = n_agents\n",
    "        self.n_act = act_dim\n",
    "        self.n_neighbor = neighbors\n",
    "        self.lamb_temp = lamb\n",
    "        self.rho = rho\n",
    "        self.t = 0\n",
    "\n",
    "    def get_action(self, graph):\n",
    "        if random.random() < self.epsilon:\n",
    "            action = torch.randint(0, n_act, size=(self.n_agents,))\n",
    "        else:\n",
    "            q_value = self.q_net(graph)\n",
    "            action = q.argmax(dim=-1).detach()\n",
    "        self.epsilon = max(self.epsilon*self.decay_rate, self.epsilon_min)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def get_q(self, graph):\n",
    "        z, weight = self.conv_net(graph)\n",
    "        self.KL_backward = self.conv_net.kl()\n",
    "        q = self.q_net(z)\n",
    "        return q, weight\n",
    "    \n",
    "    def get_target(self, graph):\n",
    "        z = self.target_conv(graph)\n",
    "        q = self.target_q(z)\n",
    "        return q\n",
    "    \n",
    "    def save_samples(self, g, a, r, n_g, t):\n",
    "        self.buffer.push(g, a, r, n_g, t)\n",
    "    \n",
    "    def fit(self):\n",
    "        if len(self.buffer) < self.batch_size*10:\n",
    "            return False, 0\n",
    "        lamb_elbo = F.sigmoid(self.rho*self.t)\n",
    "        state, act, reward, n_state, done = self.buffer.sample(self.batch_size)\n",
    "        curr_qs, curr_weight = self.get_qs(state)\n",
    "        selected_qs = curr_qs.gather(1, act).reshape(-1)\n",
    "        next_qs = self.get_target(n_state).max(dim=1)[0].detach()\n",
    "        target = reward + self.gamma * next_qs * (1 - done)\n",
    "        \n",
    "        _, next_weight = self.get_qs(n_state)\n",
    "        KL = (curr_weight * torch.log(curr_weight/next_weight)).sum(-1)\n",
    "        KL = self.lamb_temp*KL + lamb_elbo*self.conv_net.kl()\n",
    "        loss = F.mse_loss(curr_qs, target) + KL\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.target_update()\n",
    "        self.t += 1\n",
    "\n",
    "        return True, loss.item()\n",
    "    \n",
    "    def target_update(self):\n",
    "        for target, param in zip(self.target_conv.parameters(),\n",
    "                                  self.conv_net.parameters()):\n",
    "            target.data = (1-self.beta)*target.data + self.beta*param.data\n",
    "\n",
    "        for target, param in zip(self.q_net.parameters(),\n",
    "                                  self.target_q.parameters()):\n",
    "            target.data = (1-self.beta)*target.data + self.beta*param.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get graph from observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges(feature, n_agents, n_neighbor=3):\n",
    "    from_idx = [] # source\n",
    "    to_idx = [] # destination\n",
    "    dis = []\n",
    "    for src in range(n_agents):\n",
    "        x, y = feature[src][-2], feature[src][-1]\n",
    "        dis.append((x, y, src))\n",
    "    for src in range(n_agents):\n",
    "        f = []\n",
    "        for dst in range(n_agents):\n",
    "            distance = (dis[dst][0]-dis[src][0])**2+(dis[dst][1]-dis[src][1])**2\n",
    "            f.append([distance, dst])\n",
    "        f.sort(key=lambda x:x[0]) # sort w.r.t. distance\n",
    "        for order in range(n_neighbor+1):\n",
    "            from_idx.append(src)\n",
    "            to_idx.append(f[order][1])\n",
    "    return from_idx, to_idx\n",
    "\n",
    "def observation(view, feature, n_agents):\n",
    "    obs = []\n",
    "    for j in range(n_agents):\n",
    "        obs.append(np.hstack(((view[j][:,:,1]-view[j][:,:,5]).flatten(),\n",
    "                              feature[j][-1:-3:-1])))\n",
    "    return obs\n",
    "\n",
    "def gen_graph(view, feature):\n",
    "    g = dgl.DGLGraph()\n",
    "    \n",
    "    n_agents = len(feature)\n",
    "    g.add_nodes(n_agents)\n",
    "    \n",
    "    from_idx, to_idx = get_edges(feature, n_agents)\n",
    "    g.add_edges(from_idx, to_idx)\n",
    "    \n",
    "    # we save observation as the feature of the nodes\n",
    "    obs = observation(view, feature)\n",
    "    g.ndata['obs'] = torch.Tensor(obs) # shape = (n_agents, view_size**2 + 2)\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to do\n",
    "\n",
    "1) Test whether it works on \"$\\textbf{battle}$\" environment of \"Mean Field Multi-Agent Reinforcement Learning\"\n",
    "https://github.com/mlii/mfrl/blob/master/examples/battle_model/python/magent/builtin/config/battle.py\n",
    "\n",
    "2) Train models with different groups setting (DGN-R vs DGN, BAM-DGN vs DGN, ...)\n",
    "\n",
    "3) Discussion on the results & Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
